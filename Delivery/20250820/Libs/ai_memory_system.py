"""
AI Memory System for SkyNET I2A2 HR Automation
Sistema de memÃ³ria persistente para aprendizado contÃ­nuo do agente IA
"""

import json
import pickle
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import hashlib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

@dataclass
class Experience:
    """Representa uma experiÃªncia do agente IA"""
    timestamp: str
    context_hash: str
    context: Dict[str, Any]
    decision: Dict[str, Any]
    outcome: Dict[str, Any]
    performance_score: float
    feedback: Optional[Dict[str, Any]] = None
    tags: List[str] = None

    def __post_init__(self):
        if self.tags is None:
            self.tags = []

@dataclass
class LearningInsight:
    """Insight aprendido pelo agente"""
    insight_type: str
    description: str
    confidence: float
    evidence_count: int
    last_updated: str
    parameters_affected: List[str]

class AIMemorySystem:
    """
    Sistema de memÃ³ria persistente para o agente IA
    
    Funcionalidades:
    - Armazenamento de experiÃªncias
    - Busca por similaridade
    - Aprendizado com feedback
    - GeraÃ§Ã£o de insights
    - AnÃ¡lise de padrÃµes
    """
    
    def __init__(self, memory_path: str = "ai_memory"):
        self.memory_path = Path(memory_path)
        self.memory_path.mkdir(exist_ok=True)
        
        # Carregar dados existentes
        self.experiences = self._load_experiences()
        self.insights = self._load_insights()
        self.performance_history = self._load_performance_history()
        
        # Inicializar vetorizador para busca por similaridade
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self._update_vectorizer()
        
        print(f"ðŸ§  AI Memory System initialized with {len(self.experiences)} experiences")
    
    def store_experience(self, context: Dict, decision: Dict, outcome: Dict, 
                        feedback: Optional[Dict] = None) -> str:
        """
        Armazena uma nova experiÃªncia para aprendizado futuro
        
        Args:
            context: Contexto da situaÃ§Ã£o
            decision: DecisÃ£o tomada
            outcome: Resultado obtido
            feedback: Feedback opcional sobre a decisÃ£o
            
        Returns:
            ID da experiÃªncia armazenada
        """
        # Gerar hash do contexto para identificaÃ§Ã£o Ãºnica
        context_hash = self._generate_context_hash(context)
        
        # Calcular score de performance
        performance_score = self._calculate_performance_score(outcome, feedback)
        
        # Criar experiÃªncia
        experience = Experience(
            timestamp=datetime.now().isoformat(),
            context_hash=context_hash,
            context=context,
            decision=decision,
            outcome=outcome,
            performance_score=performance_score,
            feedback=feedback,
            tags=self._generate_tags(context, decision, outcome)
        )
        
        # Armazenar experiÃªncia
        self.experiences.append(experience)
        self._save_experiences()
        
        # Atualizar vetorizador
        self._update_vectorizer()
        
        # Gerar insights se necessÃ¡rio
        self._generate_insights_from_experience(experience)
        
        print(f"ðŸ’¾ Stored experience: {context_hash[:8]}... (score: {performance_score:.2f})")
        return context_hash
    
    def retrieve_similar_experiences(self, context: Dict, 
                                   similarity_threshold: float = 0.7,
                                   max_results: int = 10) -> List[Experience]:
        """
        Recupera experiÃªncias similares baseadas no contexto
        
        Args:
            context: Contexto atual para busca
            similarity_threshold: Limiar de similaridade (0-1)
            max_results: NÃºmero mÃ¡ximo de resultados
            
        Returns:
            Lista de experiÃªncias similares
        """
        if not self.experiences:
            return []
        
        # Converter contexto em texto para anÃ¡lise
        context_text = self._context_to_text(context)
        
        # Calcular similaridade
        similarities = self._calculate_similarities(context_text)
        
        # Filtrar por threshold e ordenar por similaridade
        similar_experiences = []
        for i, similarity in enumerate(similarities):
            if similarity >= similarity_threshold:
                experience = self.experiences[i]
                experience.similarity_score = similarity
                similar_experiences.append(experience)
        
        # Ordenar por similaridade e performance
        similar_experiences.sort(key=lambda x: (x.similarity_score, x.performance_score), reverse=True)
        
        return similar_experiences[:max_results]
    
    def learn_from_feedback(self, experience_id: str, feedback: Dict) -> None:
        """
        Aprende com feedback sobre uma experiÃªncia especÃ­fica
        
        Args:
            experience_id: ID da experiÃªncia
            feedback: Feedback sobre a decisÃ£o
        """
        # Encontrar experiÃªncia
        experience = self._find_experience_by_id(experience_id)
        if not experience:
            print(f"âš ï¸ Experience {experience_id} not found")
            return
        
        # Atualizar feedback
        experience.feedback = feedback
        
        # Recalcular performance score
        experience.performance_score = self._calculate_performance_score(
            experience.outcome, feedback
        )
        
        # Salvar alteraÃ§Ãµes
        self._save_experiences()
        
        # Gerar insights baseados no feedback
        self._generate_insights_from_feedback(experience, feedback)
        
        print(f"ðŸ“š Learned from feedback for experience {experience_id[:8]}...")
    
    def get_learning_insights(self, insight_type: Optional[str] = None) -> List[LearningInsight]:
        """
        Retorna insights aprendidos pelo agente
        
        Args:
            insight_type: Tipo especÃ­fico de insight (opcional)
            
        Returns:
            Lista de insights
        """
        if insight_type:
            return [insight for insight in self.insights if insight.insight_type == insight_type]
        return self.insights
    
    def analyze_performance_trends(self, days: int = 30) -> Dict[str, Any]:
        """
        Analisa tendÃªncias de performance do agente
        
        Args:
            days: NÃºmero de dias para anÃ¡lise
            
        Returns:
            AnÃ¡lise de tendÃªncias
        """
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # Filtrar experiÃªncias recentes
        recent_experiences = [
            exp for exp in self.experiences
            if datetime.fromisoformat(exp.timestamp) >= cutoff_date
        ]
        
        if not recent_experiences:
            return {"error": "No recent experiences found"}
        
        # Calcular mÃ©tricas
        scores = [exp.performance_score for exp in recent_experiences]
        
        analysis = {
            "period_days": days,
            "total_experiences": len(recent_experiences),
            "average_performance": np.mean(scores),
            "performance_std": np.std(scores),
            "performance_trend": self._calculate_trend(scores),
            "best_performance": max(scores),
            "worst_performance": min(scores),
            "improvement_rate": self._calculate_improvement_rate(recent_experiences)
        }
        
        return analysis
    
    def suggest_parameter_adjustments(self) -> Dict[str, float]:
        """
        Sugere ajustes de parÃ¢metros baseados no aprendizado
        
        Returns:
            SugestÃµes de ajuste de parÃ¢metros
        """
        if not self.experiences:
            return {}
        
        # Analisar padrÃµes de sucesso
        successful_experiences = [
            exp for exp in self.experiences 
            if exp.performance_score > 0.8
        ]
        
        if not successful_experiences:
            return {}
        
        # Extrair parÃ¢metros de decisÃµes bem-sucedidas
        parameter_suggestions = {}
        
        for exp in successful_experiences:
            decision_params = exp.decision.get('parameters', {})
            for param, value in decision_params.items():
                if param not in parameter_suggestions:
                    parameter_suggestions[param] = []
                parameter_suggestions[param].append(value)
        
        # Calcular mÃ©dias dos parÃ¢metros bem-sucedidos
        suggestions = {}
        for param, values in parameter_suggestions.items():
            if len(values) >= 3:  # MÃ­nimo de 3 experiÃªncias
                suggestions[param] = np.mean(values)
        
        return suggestions
    
    def _generate_context_hash(self, context: Dict) -> str:
        """Gera hash Ãºnico para o contexto"""
        context_str = json.dumps(context, sort_keys=True)
        return hashlib.md5(context_str.encode()).hexdigest()
    
    def _calculate_performance_score(self, outcome: Dict, feedback: Optional[Dict]) -> float:
        """Calcula score de performance baseado no resultado e feedback"""
        score = 0.0
        
        # Score baseado no resultado
        if 'accuracy' in outcome:
            score += outcome['accuracy'] * 0.4
        
        if 'total_value' in outcome and 'target_value' in outcome:
            accuracy = min(1.0, outcome['total_value'] / outcome['target_value'])
            score += accuracy * 0.3
        
        if 'employee_count' in outcome:
            # Bonus por processar muitos funcionÃ¡rios
            score += min(0.1, outcome['employee_count'] / 10000)
        
        # Score baseado no feedback
        if feedback:
            if 'satisfaction' in feedback:
                score += feedback['satisfaction'] * 0.2
            
            if 'quality_rating' in feedback:
                score += feedback['quality_rating'] * 0.1
        
        return min(1.0, max(0.0, score))
    
    def _generate_tags(self, context: Dict, decision: Dict, outcome: Dict) -> List[str]:
        """Gera tags para categorizaÃ§Ã£o da experiÃªncia"""
        tags = []
        
        # Tags baseadas no contexto
        if 'employee_count' in context:
            if context['employee_count'] > 1000:
                tags.append('large_scale')
            elif context['employee_count'] > 500:
                tags.append('medium_scale')
            else:
                tags.append('small_scale')
        
        # Tags baseadas na decisÃ£o
        if 'strategy' in decision:
            tags.append(f"strategy_{decision['strategy']}")
        
        # Tags baseadas no resultado
        if 'accuracy' in outcome:
            if outcome['accuracy'] > 0.95:
                tags.append('high_accuracy')
            elif outcome['accuracy'] > 0.90:
                tags.append('medium_accuracy')
            else:
                tags.append('low_accuracy')
        
        return tags
    
    def _context_to_text(self, context: Dict) -> str:
        """Converte contexto em texto para anÃ¡lise de similaridade"""
        text_parts = []
        
        for key, value in context.items():
            if isinstance(value, (str, int, float)):
                text_parts.append(f"{key}: {value}")
            elif isinstance(value, dict):
                text_parts.append(f"{key}: {json.dumps(value)}")
            elif isinstance(value, list):
                text_parts.append(f"{key}: {len(value)} items")
        
        return " ".join(text_parts)
    
    def _update_vectorizer(self) -> None:
        """Atualiza o vetorizador com todas as experiÃªncias"""
        if not self.experiences:
            return
        
        # Converter experiÃªncias em textos
        texts = [self._context_to_text(exp.context) for exp in self.experiences]
        
        # Treinar vetorizador
        self.vectorizer.fit(texts)
    
    def _calculate_similarities(self, context_text: str) -> List[float]:
        """Calcula similaridades entre contexto atual e experiÃªncias"""
        if not self.experiences:
            return []
        
        # Converter contexto atual em vetor
        current_vector = self.vectorizer.transform([context_text])
        
        # Converter experiÃªncias em vetores
        experience_texts = [self._context_to_text(exp.context) for exp in self.experiences]
        experience_vectors = self.vectorizer.transform(experience_texts)
        
        # Calcular similaridades
        similarities = cosine_similarity(current_vector, experience_vectors)[0]
        
        return similarities.tolist()
    
    def _find_experience_by_id(self, experience_id: str) -> Optional[Experience]:
        """Encontra experiÃªncia por ID"""
        for exp in self.experiences:
            if exp.context_hash == experience_id:
                return exp
        return None
    
    def _generate_insights_from_experience(self, experience: Experience) -> None:
        """Gera insights baseados em uma nova experiÃªncia"""
        # Insight sobre performance
        if experience.performance_score > 0.9:
            insight = LearningInsight(
                insight_type="high_performance",
                description=f"High performance achieved with {experience.decision.get('strategy', 'unknown')} strategy",
                confidence=0.8,
                evidence_count=1,
                last_updated=datetime.now().isoformat(),
                parameters_affected=list(experience.decision.get('parameters', {}).keys())
            )
            self.insights.append(insight)
        
        # Insight sobre padrÃµes
        if len(self.experiences) >= 10:
            self._analyze_patterns()
    
    def _generate_insights_from_feedback(self, experience: Experience, feedback: Dict) -> None:
        """Gera insights baseados em feedback"""
        if feedback.get('satisfaction', 0) < 0.5:
            insight = LearningInsight(
                insight_type="low_satisfaction",
                description=f"Low satisfaction reported for {experience.decision.get('strategy', 'unknown')} strategy",
                confidence=0.7,
                evidence_count=1,
                last_updated=datetime.now().isoformat(),
                parameters_affected=list(experience.decision.get('parameters', {}).keys())
            )
            self.insights.append(insight)
    
    def _analyze_patterns(self) -> None:
        """Analisa padrÃµes nas experiÃªncias"""
        # Implementar anÃ¡lise de padrÃµes
        pass
    
    def _calculate_trend(self, scores: List[float]) -> str:
        """Calcula tendÃªncia de performance"""
        if len(scores) < 2:
            return "insufficient_data"
        
        # Calcular tendÃªncia usando regressÃ£o linear simples
        x = np.arange(len(scores))
        y = np.array(scores)
        
        slope = np.polyfit(x, y, 1)[0]
        
        if slope > 0.01:
            return "improving"
        elif slope < -0.01:
            return "declining"
        else:
            return "stable"
    
    def _calculate_improvement_rate(self, experiences: List[Experience]) -> float:
        """Calcula taxa de melhoria"""
        if len(experiences) < 2:
            return 0.0
        
        # Ordenar por timestamp
        sorted_experiences = sorted(experiences, key=lambda x: x.timestamp)
        
        # Calcular melhoria
        first_half = sorted_experiences[:len(sorted_experiences)//2]
        second_half = sorted_experiences[len(sorted_experiences)//2:]
        
        first_avg = np.mean([exp.performance_score for exp in first_half])
        second_avg = np.mean([exp.performance_score for exp in second_half])
        
        return (second_avg - first_avg) / first_avg if first_avg > 0 else 0.0
    
    def _load_experiences(self) -> List[Experience]:
        """Carrega experiÃªncias do disco"""
        try:
            with open(self.memory_path / "experiences.json", 'r') as f:
                data = json.load(f)
                return [Experience(**exp) for exp in data]
        except FileNotFoundError:
            return []
    
    def _save_experiences(self) -> None:
        """Salva experiÃªncias no disco"""
        data = [asdict(exp) for exp in self.experiences]
        with open(self.memory_path / "experiences.json", 'w') as f:
            json.dump(data, f, indent=2)
    
    def _load_insights(self) -> List[LearningInsight]:
        """Carrega insights do disco"""
        try:
            with open(self.memory_path / "insights.json", 'r') as f:
                data = json.load(f)
                return [LearningInsight(**insight) for insight in data]
        except FileNotFoundError:
            return []
    
    def _save_insights(self) -> None:
        """Salva insights no disco"""
        data = [asdict(insight) for insight in self.insights]
        with open(self.memory_path / "insights.json", 'w') as f:
            json.dump(data, f, indent=2)
    
    def _load_performance_history(self) -> List[Dict]:
        """Carrega histÃ³rico de performance"""
        try:
            with open(self.memory_path / "performance_history.json", 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return []
    
    def _save_performance_history(self) -> None:
        """Salva histÃ³rico de performance"""
        with open(self.memory_path / "performance_history.json", 'w') as f:
            json.dump(self.performance_history, f, indent=2)
